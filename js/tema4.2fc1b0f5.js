(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["tema4"],{"02b1":function(a,e,i){a.exports=i.p+"img/img1.7a8b572f.png"},"1eb1":function(a,e,i){a.exports=i.p+"img/img5.83e0c964.png"},"3eb5":function(a,e,i){"use strict";i.r(e);var t=function(){var a=this,e=a._self._c;return e("div",{staticClass:"curso-main-container pb-3"},[e("BannerInterno"),e("div",{staticClass:"container tarjeta tarjeta--blanca p-4 p-md-5 mb-5"},[a._m(0),a._m(1),e("separador"),a._m(2),a._m(3),e("separador"),a._m(4),e("p",[a._v("La automatización de modelos de inteligencia artificial puede lograrse utilizando herramientas como Python, Scikit-learn, Jupyter Notebooks y Power BI, integradas en un flujo de trabajo secuencial. Cada herramienta cumple una función específica en las etapas de preparación de datos, modelado predictivo y visualización de resultados, permitiendo una orquestación eficiente y escalable mediante programación estructurada y procesos automatizados.")]),e("p",[a._v("A continuación, se describe cómo estas herramientas contribuyen al proceso de automatización:")]),e("AcordionA",{staticClass:"mb-5",attrs:{tipo:"a","clase-tarjeta":"tarjeta tarjeta--azul"}},[e("div",{staticClass:"row",attrs:{titulo:"Preparación y análisis de datos con Python y Jupyter Notebooks"}},[e("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[e("p",[a._v("Python, junto con bibliotecas como Pandas, se utiliza para automatizar la extracción y carga de datos desde fuentes diversas, como bases de datos, archivos CSV o APIs. Jupyter Notebooks proporciona un entorno interactivo para el análisis exploratorio de datos (EDA), donde se pueden desarrollar scripts reutilizables para tareas de limpieza, imputación de valores faltantes, eliminación de duplicados, transformación y codificación de variables. Esta etapa inicial, aunque puede incluir análisis manual, se automatiza mediante la generación de funciones que estandarizan el procesamiento de nuevos datos (Sahoo, 2019).")])]),e("div",{staticClass:"col-md-6"},[e("figure",[e("img",{attrs:{src:i("b807"),alt:"Texto que describa la imagen"}})])])]),e("div",{staticClass:"row",attrs:{titulo:"Modelado de inteligencia artificial con Python y Scikit-learn"}},[e("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[e("p",[a._v("Scikit-learn permite automatizar el entrenamiento de modelos mediante scripts que manejan la selección algorítmica, la división de datos en conjuntos de entrenamiento y prueba, y la capacitación del modelo. Herramientas como GridSearchCV o RandomizedSearchCV facilitan la búsqueda automatizada de los mejores hiperparámetros, optimizando así el rendimiento predictivo. Posteriormente, la evaluación del modelo se realiza de forma sistemática utilizando métricas predefinidas, y el modelo entrenado se guarda utilizando bibliotecas como Joblib o Pickle para su reutilización futura sin necesidad de reentrenamiento.")])]),e("div",{staticClass:"col-md-6"},[e("figure",[e("img",{attrs:{src:i("6065"),alt:"Texto que describa la imagen"}})])])]),e("div",{staticClass:"row",attrs:{titulo:"Visualización y presentación de resultados con Power BI"}},[e("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[e("p",[a._v("Power BI se integra como herramienta de visualización para automatizar la presentación de resultados. Puede conectarse a las fuentes donde se almacenan los datos procesados o las predicciones del modelo, permitiendo la creación de informes y dashboards que se actualizan automáticamente. Además, Power BI soporta la ejecución de scripts en Python, lo que amplía las capacidades de análisis y visualización avanzadas directamente dentro de los informes, asegurando la actualización continua de los resultados presentados.")])]),e("div",{staticClass:"col-md-6"},[e("figure",[e("img",{attrs:{src:i("55a1"),alt:"Texto que describa la imagen"}})])])]),e("div",{staticClass:"row",attrs:{titulo:"Automatización completa del flujo de trabajo"}},[e("div",{staticClass:"col-md-6 mb-4 mb-md-0"},[e("p",[a._v("La automatización total se logra mediante la escritura de "),e("i",[a._v("scripts")]),a._v(" de Python que orquestan todo el proceso, desde la recolección de datos hasta el despliegue de informes actualizados. Los Jupyter Notebooks actúan como entornos de desarrollo y documentación, mientras que en producción se pueden emplear herramientas de gestión de flujos de trabajo, como Apache Airflow o "),e("i",[a._v("schedulers")]),a._v(" de tareas, para ejecutar los procesos de forma programada, garantizando la actualización periódica de los modelos y reportes.")])]),e("div",{staticClass:"col-md-6"},[e("figure",[e("img",{attrs:{src:i("1eb1"),alt:"Texto que describa la imagen"}})])])])]),a._m(5)],1)],1)},s=[function(){var a=this,e=a._self._c;return e("div",{staticClass:"titulo-principal color-acento-contenido"},[e("div",{staticClass:"titulo-principal__numero"},[e("span",[a._v("4")])]),e("h1",[a._v("Automatización de modelos de inteligencia artificial")])])},function(){var a=this,e=a._self._c;return e("div",{staticClass:"row justify-content-center align-items-center mb-5"},[e("div",{staticClass:"col-lg-12 mb-4",attrs:{"data-aos":"zoom-in"}},[e("figure",[e("img",{attrs:{src:i("02b1"),alt:"Texto que describa la imagen"}})])]),e("div",{staticClass:"col-lg-12",attrs:{"data-aos":"flip-up"}},[e("p",[a._v('La automatización de modelos de inteligencia artificial busca reducir la intervención manual en las tareas de preparación, construcción, validación y despliegue de modelos predictivos. A través del uso de "[i pipelines] de datos y herramientas especializadas, se consigue acelerar el ciclo de vida de los proyectos de IA, mejorar la reproducibilidad de los resultados y facilitar la actualización continua de los modelos frente a nuevos datos. La automatización no solo optimiza los recursos humanos y computacionales, sino que también permite la detección temprana de desviaciones en el comportamiento del modelo, garantizando su vigencia en entornos dinámicos (Almeida, 2013).')])])])},function(){var a=this,e=a._self._c;return e("div",{staticClass:"titulo-segundo color-acento-contenido",attrs:{id:"t_4_1","data-aos":"flip-up"}},[e("h2",[a._v("4.1 Automatización de procesos de preparación y modelado de datos")])])},function(){var a=this,e=a._self._c;return e("div",{staticClass:"BG_04 p-5"},[e("p",{staticClass:"mb-4"},[a._v("Los procesos de preparación y modelado de datos son tradicionalmente intensivos en tiempo y propensos a errores si se realizan manualmente. Para evitar estas limitaciones, se implementan flujos automatizados que permiten:")]),e("div",{staticClass:"row justify-content-center align-items-center mb-4"},[e("div",{staticClass:"col-lg-12",attrs:{"data-aos":"flip-up"}},[e("div",{staticClass:"tarjeta--blanca p-5"},[e("ol",{staticClass:"lista-ol--cuadro lista-ol--separador"},[e("li",[e("div",{staticClass:"lista-ol--cuadro__vineta"},[e("span",[a._v("1")])]),a._v("La recolección periódica de nuevos datos desde diferentes fuentes (APIs, bases de datos y sistemas LMS).")]),e("li",[e("div",{staticClass:"lista-ol--cuadro__vineta"},[e("span",[a._v("2")])]),a._v("La ejecución sistemática de rutinas de limpieza, imputación de datos faltantes, detección de valores atípicos y normalización de variables.")]),e("li",[e("div",{staticClass:"lista-ol--cuadro__vineta"},[e("span",[a._v("3")])]),a._v("La generación automática de variables derivadas y enriquecimiento de los datasets.")]),e("li",[e("div",{staticClass:"lista-ol--cuadro__vineta"},[e("span",[a._v("4")])]),a._v("La actualización dinámica de particiones de entrenamiento y prueba conforme llegan nuevos datos.")]),e("li",[e("div",{staticClass:"lista-ol--cuadro__vineta"},[e("span",[a._v("5")])]),e("p",{staticClass:"mb-0"},[a._v("El reentrenamiento programado de modelos de "),e("i",[a._v("machine learning")]),a._v(", considerando validaciones cruzadas y evaluaciones de desempeño periódicas.")])])])])])]),e("p",[a._v("Esta automatización se logra mediante la construcción de "),e("i",[a._v("pipelines")]),a._v(" que conectan las etapas de forma orquestada, utilizando herramientas de orquestación de flujos de trabajo como Apache Airflow, Kubeflow Pipelines o servicios integrados en plataformas en la nube.")])])},function(){var a=this,e=a._self._c;return e("div",{staticClass:"titulo-segundo color-acento-contenido",attrs:{id:"t_4_2","data-aos":"flip-up"}},[e("h2",[a._v("4.2 Automatización mediante herramientas especializadas")])])},function(){var a=this,e=a._self._c;return e("p",[a._v("Esta integración coordinada de herramientas facilita la construcción de "),e("i",[a._v("pipelines")]),a._v(" robustos de inteligencia artificial, mejorando la eficiencia, reduciendo errores y permitiendo una respuesta ágil ante cambios en los datos o en las necesidades del negocio.")])}],o={name:"Tema4",data:()=>({}),mounted(){this.$nextTick(()=>{this.$aosRefresh()})},updated(){this.$aosRefresh()}},n=o,r=i("2877"),c=Object(r["a"])(n,t,s,!1,null,null,null);e["default"]=c.exports},"55a1":function(a,e,i){a.exports=i.p+"img/img4.f918ceaa.png"},6065:function(a,e,i){a.exports=i.p+"img/img3.a4ee8a09.png"},b807:function(a,e,i){a.exports=i.p+"img/img2.8303883b.png"}}]);
//# sourceMappingURL=tema4.2fc1b0f5.js.map